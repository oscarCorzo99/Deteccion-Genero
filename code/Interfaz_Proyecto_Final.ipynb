{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BHtTFOrRYBU",
        "outputId": "b29934f9-2a33-4029-ce5b-63baebf7af29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading files from the demo repo\n",
        "import os\n",
        "os.mkdir('/Audio')\n",
        "!wget -q -O /Audio/blues.00014.wav https://github.com/oscarCorzo99/Deteccion-Genero/raw/main/Audios/blues.00014.wav\n",
        "!wget -q -O /Audio/country.00011.wav https://github.com/oscarCorzo99/Deteccion-Genero/raw/main/Audios/country.00011.wav\n",
        "!wget -q -O /Audio/metal.00017.wav https://github.com/oscarCorzo99/Deteccion-Genero/raw/main/Audios/metal.00017.wav"
      ],
      "metadata": {
        "id": "atBe97uq9n8r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O /scaler_regression.sav https://github.com/oscarCorzo99/Deteccion-Genero/raw/main/Log-Reg/scaler_regression.sav\n",
        "!wget -q -O /finalized_model_regression.sav https://github.com/oscarCorzo99/Deteccion-Genero/raw/main/Log-Reg/finalized_model_regression.sav\n",
        "!wget -q -O /finalized_model_RandomF.sav https://github.com/oscarCorzo99/Deteccion-Genero/raw/main/Random-Forest/finalized_model_RandomF.sav"
      ],
      "metadata": {
        "id": "BvBerdue_MXQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import librosa\n",
        "import librosa.feature as Aud\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pickle\n",
        "\n",
        "Models = [\"Logistic Reg.\",\"Random Forest\"]\n",
        "\n",
        "loaded_scaler = pickle.load(open('/scaler_regression.sav', 'rb'))\n",
        "loaded_model_Reg = pickle.load(open('/finalized_model_regression.sav', 'rb'))\n",
        "loaded_model_Forest = pickle.load(open('/finalized_model_RandomF.sav', 'rb'))\n",
        "\n",
        "def build_record(sr, x):\n",
        "  record = {}\n",
        "  chroma = Aud.chroma_stft(y=x, sr=sr)\n",
        "  rms = Aud.rms(y=x)\n",
        "  cent = Aud.spectral_centroid(y=x, sr=sr)\n",
        "  spec_bw = Aud.spectral_bandwidth(y=x, sr=sr)\n",
        "  rolloff = Aud.spectral_rolloff(y=x, sr=sr)\n",
        "  zero_cross = Aud.zero_crossing_rate(x)\n",
        "  onset_env = librosa.onset.onset_strength(y=x, sr=sr)\n",
        "  tempo = Aud.tempo(onset_envelope=onset_env, sr=sr)\n",
        "\n",
        "  record['chroma_stft_mean'] = np.mean(chroma)\n",
        "  record['chroma_stft_var'] = np.var(chroma)\n",
        "  record['rms_mean'] = np.mean(rms)\n",
        "  record['rms_var'] = np.var(rms)\n",
        "  record['spectral_centroid_mean'] = np.mean(cent)\n",
        "  record['spectral_centroid_var'] = np.var(cent)\n",
        "  record['spectral_bandwidth_mean'] = np.mean(spec_bw)\n",
        "  record['spectral_bandwidth_var'] = np.var(spec_bw)\n",
        "  record['rolloff_mean'] = np.mean(rolloff)\n",
        "  record['rolloff_var'] = np.var(rolloff)\n",
        "  record['zero_crossing_rate_mean'] = np.mean(zero_cross)\n",
        "  record['zero_crossing_rate_var'] = np.var(zero_cross)\n",
        "  record['tempo'] = tempo\n",
        "\n",
        "  mfccs = Aud.mfcc(y = x, sr = sr)\n",
        "  for i in range(mfccs.shape[0]):\n",
        "    key_m = 'mfcc' + str(i+1) + '_mean'\n",
        "    key_v = 'mfcc' + str(i+1) + '_var'\n",
        "    record[key_m] = np.mean(mfccs[i,:])\n",
        "    record[key_v] = np.var(mfccs[i,:])\n",
        "\n",
        "  return record\n",
        "\n",
        "def Logistic_Regression(X):\n",
        "  # load the model from disk\n",
        "  scaled_vals = loaded_scaler.transform(X)\n",
        "  result = loaded_model_Reg.predict(scaled_vals)\n",
        "  return result\n",
        "\n",
        "def Random_Forest(X):\n",
        "  # load the model from disk\n",
        "  result = loaded_model_Forest.predict(X)\n",
        "  return result\n",
        "\n",
        "def main_note(audio,model):\n",
        "    #sr, x = audio\n",
        "    x , sr = librosa.load(audio, sr=None)\n",
        "    #print(type(sr),type(x))\n",
        "    registro = build_record(sr, x)\n",
        "    df = pd.DataFrame(registro)\n",
        "    df = df.values\n",
        "    out_ = \"Nothing\"\n",
        "\n",
        "    if model == 0:\n",
        "      out_ = Logistic_Regression(df)\n",
        "    elif model == 1:\n",
        "      out_ = Random_Forest(df)\n",
        "\n",
        "    return out_[0]\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    main_note,\n",
        "    [\n",
        "        gr.Audio(type='filepath'),\n",
        "        gr.Dropdown(Models, type=\"index\")\n",
        "    ],\n",
        "    #gr.Label(label='Info de la pista', num_top_classes = 6),\n",
        "    gr.Textbox(value=\"\", label=\"Género de la pista\", interactive=False),\n",
        "    examples=[\n",
        "        [os.path.join('/',\"Audio/blues.00014.wav\")],\n",
        "        [os.path.join('/',\"Audio/country.00011.wav\")],\n",
        "        [os.path.join('/',\"Audio/metal.00017.wav\")]\n",
        "    ],\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "F9Vriojzupx6",
        "outputId": "ec6f8975-a00a-4932-89e1-7d28f2470a40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://19322a309239a31241.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://19322a309239a31241.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://19322a309239a31241.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dSkDOWQN70or"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}